# -*- coding: utf-8 -*-
"""assignment2.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1wIxUwYa58xCVXhDS-XMmDG_xPUOI7gaT
"""

import pandas as pd
import numpy as np
from xgboost import XGBClassifier
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score
import joblib

# URLs for dataset
train_csv = "https://github.com/dustywhite7/Econ8310/raw/master/AssignmentData/assignment3.csv"
test_csv = "https://github.com/dustywhite7/Econ8310/raw/master/AssignmentData/assignment3test.csv"

# Load and prepare training data
train_df = pd.read_csv(train_csv)
target = train_df['meal']
features = train_df.drop(columns=['meal', 'id', 'DateTime'], errors='ignore')
features = pd.get_dummies(features, drop_first=True)

# Split training data into train/test subsets
X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.1, random_state=42)

# Define and train XGBoost model
xgb_model = XGBClassifier(
    n_estimators=100,
    max_depth=8,
    learning_rate=0.2,
    objective='binary:logistic',
    random_state=42
)
fitted_model = xgb_model.fit(X_train, y_train)

# Load and prepare test data
new_data = pd.read_csv(test_csv)
new_data = new_data.drop(columns=['id', 'DateTime'], errors='ignore')
new_data = pd.get_dummies(new_data, drop_first=True)
new_data = new_data.reindex(columns=features.columns, fill_value=0)

# Predict with trained model
predictions = fitted_model.predict(new_data)
predictions = list(map(int, predictions))  # Ensure native int

# Save predictions to CSV
pd.DataFrame(predictions, columns=["meal_prediction"]).to_csv("predictions.csv", index=False)

# Save trained model
joblib.dump(fitted_model, "modelFit.pkl")

# Output sample predictions
if __name__ == "__main__":
    print("Sample predictions:")
    print(predictions[:5])
    print("Best model selected and predictions saved successfully.")